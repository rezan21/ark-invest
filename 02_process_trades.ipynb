{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:00<00:00, 34497.36it/s]\n",
      "  0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fund        date direction ticker      cusip  \\\n",
      "0  ARKG  2021-02-01       Buy   CDXS  192005106   \n",
      "1  ARKG  2021-02-01       Buy   RPTX  760273102   \n",
      "2  ARKG  2021-02-01      Sell   PACB  69404D108   \n",
      "\n",
      "                                 company  shares  % of etf  \n",
      "0                            CODEXIS INC   62497    0.0134  \n",
      "1                REPARE THERAPEUTICS INC   10283    0.0034  \n",
      "2  PACIFIC BIOSCIENCES OF CALIFORNIA INC  210508    0.0645  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 3/12 [00:19<00:57,  6.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data fetched for symbol 1833 using YahooDailyReader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 11/12 [01:43<00:13, 13.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data fetched for symbol 1833 using YahooDailyReader\n",
      "No data fetched for symbol ADYEN using YahooDailyReader\n",
      "No data fetched for symbol 3690 using YahooDailyReader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [01:56<00:00,  9.75s/it]\n",
      "100%|██████████| 12/12 [00:00<00:00, 66.95it/s]\n",
      "  0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 fund        date direction ticker      cusip  \\\n",
      "key1                                                            \n",
      "API_2021-02-01   ARKW  2021-02-01      Sell    API  00851L103   \n",
      "AVAV_2021-02-01  ARKQ  2021-02-01      Sell   AVAV  008073108   \n",
      "BEAM_2021-02-01  ARKK  2021-02-01       Buy   BEAM  07373V105   \n",
      "\n",
      "                               company  shares  % of etf        Open  \n",
      "key1                                                                  \n",
      "API_2021-02-01               AGORA INC   54100    0.0577   72.080002  \n",
      "AVAV_2021-02-01      AEROVIRONMENT INC    6132    0.0241  120.040001  \n",
      "BEAM_2021-02-01  BEAM THERAPEUTICS INC   58218    0.0241   99.709999  \n",
      "         date  fund ticker                     company signal  shares  \\\n",
      "0  2021-02-10  ARKW    API                   AGORA INC   Sell  -17639   \n",
      "1  2021-02-10  ARKG   CDNA                  CAREDX INC   Sell  -76084   \n",
      "2  2021-02-10  ARKQ   EXPC  EXPERIENCE INVESTMENT CORP    Buy   36147   \n",
      "\n",
      "         Open        volume    abs_volume  \n",
      "0  100.000000 -1.763900e+06  1.763900e+06  \n",
      "1   90.508003 -6.886211e+06  6.886211e+06  \n",
      "2   17.320000  6.260660e+05  6.260660e+05  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:00<00:00, 298.51it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run ./utils.py\n",
    "\n",
    "import concurrent.futures\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "from tqdm import tqdm\n",
    "max_workers = 3\n",
    "\n",
    "\n",
    "def main():\n",
    "    # read unprocessed dfs\n",
    "    processed_trades = set([path.name for path in Path(\"./trades/processed/\").glob(\"*.csv\")])\n",
    "    raw_trades = set([path.name for path in Path(\"./trades/raw/\").glob(\"*.csv\")])\n",
    "    unprocessed_trades = raw_trades.difference(processed_trades)\n",
    "    if len(unprocessed_trades)==0:\n",
    "        return \"Nothing to Process\"\n",
    "    dfs = UtilsIO.parallel_read_df(files=[f\"./trades/raw/{name}\" for name in unprocessed_trades], returns=\"list\")\n",
    "    print(dfs[0].head(3))\n",
    "    \n",
    "    \n",
    "    # open prices of traded stocks\n",
    "    def get_trade_openings(df_):\n",
    "        df = df_.copy()\n",
    "        if df[\"date\"].nunique()!=1:\n",
    "            raise ValueError(\"number of unique dates should be 1\")\n",
    "        else:\n",
    "            # set date\n",
    "            trade_date = df.iloc[0][\"date\"]\n",
    "\n",
    "        # date's open price\n",
    "        open_configs = [{\"ticker\":ticker, \"date\":trade_date, \"on\":\"Open\"} for ticker in df[\"ticker\"].unique()] # on ark's trade date\n",
    "        open_prices = UtilsFinancial.parallel_fetch_yahoo_daily(open_configs)\n",
    "\n",
    "        # join key: date + ticker\n",
    "        open_prices[\"key1\"] = open_prices[\"ticker\"].astype(str) + \"_\" + open_prices[\"Date\"].astype(str)\n",
    "        df[\"key1\"] = df[\"ticker\"].astype(str) + \"_\" + df[\"date\"].astype(str)\n",
    "        df = df.set_index(\"key1\").join(open_prices.set_index(\"key1\")[[\"Open\"]], how=\"inner\")\n",
    "        df.drop_duplicates(inplace=True)\n",
    "\n",
    "        return df\n",
    "    priced_trades = []\n",
    "    for df_ in tqdm(dfs):\n",
    "        priced_trades.append(get_trade_openings(df_))\n",
    "    print(priced_trades[0].head(3))\n",
    "    \n",
    "    \n",
    "    # net & volume of trades (assume on open price)\n",
    "    def estimate_volume(priced_df):\n",
    "        net = priced_df.copy()[[\"fund\", \"date\", \"direction\", \"ticker\", \"company\", \"shares\", \"Open\"]]\n",
    "        net[\"shares\"] = net.apply(lambda row:row[\"shares\"] if row[\"direction\"]==\"Buy\" else -row[\"shares\"], axis=1)\n",
    "        net = net.groupby([\"ticker\", \"date\", \"company\", \"fund\"], as_index=False).agg({'shares':'sum', 'Open':'mean'})\n",
    "        # new cols\n",
    "        net[\"signal\"] = net[\"shares\"].apply(lambda x: \"Buy\" if x>0 else \"Sell\")\n",
    "        net[\"volume\"] = net[\"shares\"] * net[\"Open\"]\n",
    "        net[\"abs_volume\"] = abs(net[\"volume\"])\n",
    "        # reorder\n",
    "        net = net[[\"date\", \"fund\", \"ticker\", \"company\", \"signal\", \"shares\", \"Open\", \"volume\", \"abs_volume\"]]\n",
    "        return net\n",
    "    nets = [] # list of dfs\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
    "        nets.extend(tqdm(executor.map(estimate_volume, priced_trades), total=len(priced_trades)))\n",
    "    print(nets[-1].head(3))\n",
    "    \n",
    "    \n",
    "    # save processed locally\n",
    "    def save_processed_dfs(processed_df):\n",
    "        if processed_df[\"date\"].nunique()!=1:\n",
    "            raise ValueError(\"more than 1 value for date\")\n",
    "        trade_date = processed_df[\"date\"].iloc[0]\n",
    "        processed_df.sort_values(\"abs_volume\", ascending=False).\\\n",
    "        to_csv(f\"./trades/processed/{trade_date}_ARK_TRADES.csv\", index=False)\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        list(tqdm(executor.map(save_processed_dfs, nets), total=len(nets)))\n",
    "    \n",
    "    \n",
    "    return \"OK\"\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
