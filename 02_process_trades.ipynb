{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 4048.56it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fund        date direction ticker      cusip             company  shares  \\\n",
      "0  ARKG  2021-02-18       Buy   VEEV  922475108   VEEVA SYSTEMS INC   40818   \n",
      "1  ARKG  2021-02-18       Buy   SGFY  82671G100  SIGNIFY HEALTH INC   44305   \n",
      "2  ARKG  2021-02-18       Buy   MASS  65443P102     908 DEVICES INC    6191   \n",
      "\n",
      "   % of etf  \n",
      "0    0.1036  \n",
      "1    0.0135  \n",
      "2    0.0032  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.83s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00, 49.20it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 102.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 fund        date direction ticker      cusip  \\\n",
      "key1                                                            \n",
      "ABBV_2021-02-18  ARKG  2021-02-18       Buy   ABBV  00287Y109   \n",
      "AVAV_2021-02-18  ARKQ  2021-02-18      Sell   AVAV  008073108   \n",
      "BEAM_2021-02-18  ARKK  2021-02-18       Buy   BEAM  07373V105   \n",
      "\n",
      "                               company  shares  % of etf        Open  \n",
      "key1                                                                  \n",
      "ABBV_2021-02-18             ABBVIE INC  186105    0.1605  105.320000  \n",
      "AVAV_2021-02-18      AEROVIRONMENT INC     400    0.0013  127.970001  \n",
      "BEAM_2021-02-18  BEAM THERAPEUTICS INC   59522    0.0225  102.180000  \n",
      "         date  fund ticker                company signal  shares        Open  \\\n",
      "0  2021-02-18  ARKG   ABBV             ABBVIE INC    Buy  186105  105.320000   \n",
      "1  2021-02-18  ARKQ   AVAV      AEROVIRONMENT INC   Sell    -400  127.970001   \n",
      "2  2021-02-18  ARKK   BEAM  BEAM THERAPEUTICS INC    Buy   59522  102.180000   \n",
      "\n",
      "         volume    abs_volume  \n",
      "0  1.960058e+07  1.960058e+07  \n",
      "1 -5.118800e+04  5.118800e+04  \n",
      "2  6.081958e+06  6.081958e+06  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run ./utils.py\n",
    "\n",
    "import concurrent.futures\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "from tqdm import tqdm\n",
    "max_workers = 3\n",
    "\n",
    "\n",
    "def main():\n",
    "    # read unprocessed dfs\n",
    "    processed_trades = set([path.name for path in Path(\"./trades/processed/\").glob(\"*.csv\")])\n",
    "    raw_trades = set([path.name for path in Path(\"./trades/raw/\").glob(\"*.csv\")])\n",
    "    unprocessed_trades = raw_trades.difference(processed_trades)\n",
    "    if len(unprocessed_trades)==0:\n",
    "        return \"Nothing to Process\"\n",
    "    dfs = UtilsIO.parallel_read_df(files=[f\"./trades/raw/{name}\" for name in unprocessed_trades], returns=\"list\")\n",
    "    print(dfs[0].head(3))\n",
    "    \n",
    "    \n",
    "    # open prices of traded stocks\n",
    "    def get_trade_openings(df_):\n",
    "        df = df_.copy()\n",
    "        if df[\"date\"].nunique()!=1:\n",
    "            raise ValueError(\"number of unique dates should be 1\")\n",
    "        else:\n",
    "            # set date\n",
    "            trade_date = df.iloc[0][\"date\"]\n",
    "\n",
    "        # date's open price\n",
    "        open_configs = [{\"ticker\":ticker, \"date\":trade_date, \"on\":\"Open\"} for ticker in df[\"ticker\"].unique()] # on ark's trade date\n",
    "        open_prices = UtilsFinancial.parallel_fetch_yahoo_daily(open_configs)\n",
    "\n",
    "        # join key: date + ticker\n",
    "        open_prices[\"key1\"] = open_prices[\"ticker\"].astype(str) + \"_\" + open_prices[\"Date\"].astype(str)\n",
    "        df[\"key1\"] = df[\"ticker\"].astype(str) + \"_\" + df[\"date\"].astype(str)\n",
    "        df = df.set_index(\"key1\").join(open_prices.set_index(\"key1\")[[\"Open\"]], how=\"inner\")\n",
    "        df.drop_duplicates(inplace=True)\n",
    "\n",
    "        return df\n",
    "    priced_trades = []\n",
    "    for df_ in tqdm(dfs):\n",
    "        priced_trades.append(get_trade_openings(df_))\n",
    "    print(priced_trades[0].head(3))\n",
    "    \n",
    "    \n",
    "    # net & volume of trades (assume on open price)\n",
    "    def estimate_volume(priced_df):\n",
    "        net = priced_df.copy()[[\"fund\", \"date\", \"direction\", \"ticker\", \"company\", \"shares\", \"Open\"]]\n",
    "        net[\"shares\"] = net.apply(lambda row:row[\"shares\"] if row[\"direction\"]==\"Buy\" else -row[\"shares\"], axis=1)\n",
    "        net = net.groupby([\"ticker\", \"date\", \"company\", \"fund\"], as_index=False).agg({'shares':'sum', 'Open':'mean'})\n",
    "        # new cols\n",
    "        net[\"signal\"] = net[\"shares\"].apply(lambda x: \"Buy\" if x>0 else \"Sell\")\n",
    "        net[\"volume\"] = net[\"shares\"] * net[\"Open\"]\n",
    "        net[\"abs_volume\"] = abs(net[\"volume\"])\n",
    "        # reorder\n",
    "        net = net[[\"date\", \"fund\", \"ticker\", \"company\", \"signal\", \"shares\", \"Open\", \"volume\", \"abs_volume\"]]\n",
    "        return net\n",
    "    nets = [] # list of dfs\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
    "        nets.extend(tqdm(executor.map(estimate_volume, priced_trades), total=len(priced_trades)))\n",
    "    print(nets[-1].head(3))\n",
    "    \n",
    "    \n",
    "    # save processed locally\n",
    "    def save_processed_dfs(processed_df):\n",
    "        if processed_df[\"date\"].nunique()!=1:\n",
    "            raise ValueError(\"more than 1 value for date\")\n",
    "        trade_date = processed_df[\"date\"].iloc[0]\n",
    "        processed_df.sort_values(\"abs_volume\", ascending=False).\\\n",
    "        to_csv(f\"./trades/processed/{trade_date}_ARK_TRADES.csv\", index=False)\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        list(tqdm(executor.map(save_processed_dfs, nets), total=len(nets)))\n",
    "    \n",
    "    \n",
    "    return \"OK\"\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
