{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 7876.63it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fund        date direction ticker      cusip         company  shares  \\\n",
      "0  ARKQ  2021-03-05      Sell   AAPL   37833100       APPLE INC   27787   \n",
      "1  ARKG  2021-03-05       Buy   ACCD  4.37E+104    ACCOLADE INC  206960   \n",
      "2  ARKQ  2021-03-05      Sell   AMZN   23135106  AMAZON.COM INC    1303   \n",
      "\n",
      "   % of etf  \n",
      "0    0.1004  \n",
      "1    0.0824  \n",
      "2    0.1169  \n",
      "No data fetched for symbol KSPILI using YahooDailyReader\n",
      "No data fetched for symbol LSPDCN using YahooDailyReader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:12<00:12, 12.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data fetched for symbol KSPILI using YahooDailyReader\n",
      "No data fetched for symbol LSPDCN using YahooDailyReader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:21<00:00, 10.87s/it]\n",
      "100%|██████████| 2/2 [00:00<00:00, 57.46it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 135.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 fund        date direction ticker      cusip         company  \\\n",
      "key1                                                                            \n",
      "AAPL_2021-03-05  ARKQ  2021-03-05      Sell   AAPL   37833100       APPLE INC   \n",
      "ACCD_2021-03-05  ARKG  2021-03-05       Buy   ACCD  4.37E+104    ACCOLADE INC   \n",
      "AMZN_2021-03-05  ARKQ  2021-03-05      Sell   AMZN   23135106  AMAZON.COM INC   \n",
      "\n",
      "                 shares  % of etf         Open  \n",
      "key1                                            \n",
      "AAPL_2021-03-05   27787    0.1004   120.980003  \n",
      "ACCD_2021-03-05  206960    0.0824    39.310001  \n",
      "AMZN_2021-03-05    1303    0.1169  3005.000000  \n",
      "         date  fund ticker         company signal  shares         Open  \\\n",
      "0  2021-03-08  ARKG   ACCD    ACCOLADE INC    Buy   75140    40.110001   \n",
      "1  2021-03-08  ARKQ   AMZN  AMAZON.COM INC   Sell    -297  3015.000000   \n",
      "2  2021-03-08  ARKQ   AONE             ONE    Buy   13118    11.430000   \n",
      "\n",
      "         volume    abs_volume  \n",
      "0  3.013865e+06  3.013865e+06  \n",
      "1 -8.954550e+05  8.954550e+05  \n",
      "2  1.499387e+05  1.499387e+05  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run ./utils.py\n",
    "\n",
    "import concurrent.futures\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "from tqdm import tqdm\n",
    "max_workers = 3\n",
    "\n",
    "\n",
    "def main():\n",
    "    # read unprocessed dfs\n",
    "    processed_trades = set([path.name for path in Path(\"./trades/processed/\").glob(\"*.csv\")])\n",
    "    raw_trades = set([path.name for path in Path(\"./trades/raw/\").glob(\"*.csv\")])\n",
    "    unprocessed_trades = raw_trades.difference(processed_trades)\n",
    "    if len(unprocessed_trades)==0:\n",
    "        return \"Nothing to Process\"\n",
    "    dfs = UtilsIO.parallel_read_df(files=[f\"./trades/raw/{name}\" for name in unprocessed_trades], returns=\"list\")\n",
    "    print(dfs[0].head(3))\n",
    "    \n",
    "    \n",
    "    # open prices of traded stocks\n",
    "    def get_trade_openings(df_):\n",
    "        df = df_.copy()\n",
    "        if df[\"date\"].nunique()!=1:\n",
    "            raise ValueError(\"number of unique dates should be 1\")\n",
    "        else:\n",
    "            # set date\n",
    "            trade_date = df.iloc[0][\"date\"]\n",
    "\n",
    "        # date's open price\n",
    "        open_configs = [{\"ticker\":ticker, \"date\":trade_date, \"on\":\"Open\"} for ticker in df[\"ticker\"].unique()] # on ark's trade date\n",
    "        open_prices = UtilsFinancial.parallel_fetch_yahoo_daily(open_configs)\n",
    "\n",
    "        # join key: date + ticker\n",
    "        open_prices[\"key1\"] = open_prices[\"ticker\"].astype(str) + \"_\" + open_prices[\"Date\"].astype(str)\n",
    "        df[\"key1\"] = df[\"ticker\"].astype(str) + \"_\" + df[\"date\"].astype(str)\n",
    "        df = df.set_index(\"key1\").join(open_prices.set_index(\"key1\")[[\"Open\"]], how=\"inner\")\n",
    "        df.drop_duplicates(inplace=True)\n",
    "\n",
    "        return df\n",
    "    priced_trades = []\n",
    "    for df_ in tqdm(dfs):\n",
    "        priced_trades.append(get_trade_openings(df_))\n",
    "    print(priced_trades[0].head(3))\n",
    "    \n",
    "    \n",
    "    # net & volume of trades (assume on open price)\n",
    "    def estimate_volume(priced_df):\n",
    "        net = priced_df.copy()[[\"fund\", \"date\", \"direction\", \"ticker\", \"company\", \"shares\", \"Open\"]]\n",
    "        net[\"shares\"] = net.apply(lambda row:row[\"shares\"] if row[\"direction\"]==\"Buy\" else -row[\"shares\"], axis=1)\n",
    "        net = net.groupby([\"ticker\", \"date\", \"company\", \"fund\"], as_index=False).agg({'shares':'sum', 'Open':'mean'})\n",
    "        # new cols\n",
    "        net[\"signal\"] = net[\"shares\"].apply(lambda x: \"Buy\" if x>0 else \"Sell\")\n",
    "        net[\"volume\"] = net[\"shares\"] * net[\"Open\"]\n",
    "        net[\"abs_volume\"] = abs(net[\"volume\"])\n",
    "        # reorder\n",
    "        net = net[[\"date\", \"fund\", \"ticker\", \"company\", \"signal\", \"shares\", \"Open\", \"volume\", \"abs_volume\"]]\n",
    "        return net\n",
    "    nets = [] # list of dfs\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
    "        nets.extend(tqdm(executor.map(estimate_volume, priced_trades), total=len(priced_trades)))\n",
    "    print(nets[-1].head(3))\n",
    "    \n",
    "    \n",
    "    # save processed locally\n",
    "    def save_processed_dfs(processed_df):\n",
    "        if processed_df[\"date\"].nunique()!=1:\n",
    "            raise ValueError(\"more than 1 value for date\")\n",
    "        trade_date = processed_df[\"date\"].iloc[0]\n",
    "        processed_df.sort_values(\"abs_volume\", ascending=False).\\\n",
    "        to_csv(f\"./trades/processed/{trade_date}_ARK_TRADES.csv\", index=False)\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        list(tqdm(executor.map(save_processed_dfs, nets), total=len(nets)))\n",
    "    \n",
    "    \n",
    "    return \"OK\"\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
